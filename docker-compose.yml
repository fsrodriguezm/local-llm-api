services:
  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    ports:
      - "8080:8080"
    volumes:
      - ./searxng.settings.yml:/etc/searxng/settings.yml:ro
    environment:
      - BASE_URL=http://localhost:8080
      - INSTANCE_NAME=SearxNG
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - llm-network

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: local-llm-api
    ports:
      - "8000:8000"
    environment:
      - SEARXNG_URL=http://searxng:8080
      - DEFAULT_MODEL=${DEFAULT_MODEL:-qwen2.5-coder:3b}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      searxng:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - llm-network

networks:
  llm-network:
    driver: bridge
